{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0      1       0       0       0       0       0       0       0       0   \n",
      "1      0       0       0       0       0       0       0       0       0   \n",
      "2      1       0       0       0       0       0       0       0       0   \n",
      "3      4       0       0       0       0       0       0       0       0   \n",
      "4      0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
      "0       0    ...            0         0         0         0         0   \n",
      "1       0    ...            0         0         0         0         0   \n",
      "2       0    ...            0         0         0         0         0   \n",
      "3       0    ...            0         0         0         0         0   \n",
      "4       0    ...            0         0         0         0         0   \n",
      "\n",
      "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0         0  \n",
      "1         0         0         0         0         0  \n",
      "2         0         0         0         0         0  \n",
      "3         0         0         0         0         0  \n",
      "4         0         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "#Name - Uma K\n",
    "#Roll - BF18BDV010\n",
    "import pandas as pd\n",
    "digit_dataset=pd.read_csv(\"/home/uma/Downloads/all/train.csv\")\n",
    "print(digit_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=digit_dataset[list(digit_dataset.columns[1:])]\n",
    "y=digit_dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784)\n",
      "(42000,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uma/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.66095038\n",
      "Iteration 2, loss = 0.88846465\n",
      "Iteration 3, loss = 0.52152948\n",
      "Iteration 4, loss = 0.33344457\n",
      "Iteration 5, loss = 0.26729924\n",
      "Iteration 6, loss = 0.19947460\n",
      "Iteration 7, loss = 0.16361567\n",
      "Iteration 8, loss = 0.15290237\n",
      "Iteration 9, loss = 0.13831210\n",
      "Iteration 10, loss = 0.10967021\n",
      "Iteration 11, loss = 0.15594759\n",
      "Iteration 12, loss = 0.12390616\n",
      "Iteration 13, loss = 0.10592691\n",
      "Iteration 14, loss = 0.10422348\n",
      "Iteration 15, loss = 0.11140519\n",
      "Iteration 16, loss = 0.10074862\n",
      "Iteration 17, loss = 0.12621988\n",
      "Iteration 18, loss = 0.14351292\n",
      "Iteration 19, loss = 0.15389896\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "MLP model :  MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(400,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=True,\n",
      "       warm_start=False)\n",
      " NN accuracy : 0.961031746031746\n",
      "NN F1 :  0.9610539779065983\n",
      "NN CM :  [[1167    0   13    3    2    5    3    3    0    4]\n",
      " [   0 1375    6    2    0    0    0    2    3    1]\n",
      " [   0    1 1251   14    4    0    0   14    8    2]\n",
      " [   3    1   10 1287    0   16    0    7   11   20]\n",
      " [   2    5    6    1 1151    1    7    6    1   42]\n",
      " [   1    0    0   39    0 1027    7    0    3    8]\n",
      " [   6    1    4    2    2    7 1229    0    4    1]\n",
      " [   0    5    7    1    9    2    0 1318    0   17]\n",
      " [   2    9    8   14   10   29    5    4 1112   16]\n",
      " [   7    0    0    3   10    6    1   12    0 1192]]\n"
     ]
    }
   ],
   "source": [
    "mlp=MLPClassifier(\n",
    "    solver='adam',\n",
    "    alpha=1e-2,\n",
    "    hidden_layer_sizes=(400,),\n",
    "    random_state=1,\n",
    "    verbose=True)\n",
    "mlp.fit(x_train,y_train)\n",
    "print(\"MLP model : \",mlp)\n",
    "y_pred=mlp.predict(x_test)\n",
    "print(\" NN accuracy :\",accuracy_score(y_test,y_pred))\n",
    "print(\"NN F1 : \",f1_score(y_test,y_pred,average=\"weighted\"))\n",
    "print(\"NN CM : \",confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_test=pd.read_csv(\"/home/uma/Downloads/all/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
      "0       0       0       0       0       0       0       0       0       0   \n",
      "1       0       0       0       0       0       0       0       0       0   \n",
      "2       0       0       0       0       0       0       0       0       0   \n",
      "3       0       0       0       0       0       0       0       0       0   \n",
      "4       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
      "0       0    ...            0         0         0         0         0   \n",
      "1       0    ...            0         0         0         0         0   \n",
      "2       0    ...            0         0         0         0         0   \n",
      "3       0    ...            0         0         0         0         0   \n",
      "4       0    ...            0         0         0         0         0   \n",
      "\n",
      "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0         0  \n",
      "1         0         0         0         0         0  \n",
      "2         0         0         0         0         0  \n",
      "3         0         0         0         0         0  \n",
      "4         0         0         0         0         0  \n",
      "\n",
      "[5 rows x 784 columns]\n"
     ]
    }
   ],
   "source": [
    "print(digit_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test=mlp.predict(digit_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 9 ... 3 9 2]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(digit_dataset['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self -made function for k-fold generation\n",
    "def fold_generator(): \n",
    "    k=int(input(\"Enter the number of folds : \\n \"))\n",
    "    l=len(digit_dataset['label'])\n",
    "    fold_len=int(l/k)\n",
    "    print(fold_len)\n",
    "    size=list()\n",
    "    controller=0\n",
    "    t=tuple()\n",
    "    for i in range(k):\n",
    "       if i==0:\n",
    "        t=(i,i+fold_len+1)\n",
    "        size.append(t)\n",
    "        controller=i+fold_len+1\n",
    "       elif i==(k-1):\n",
    "        t=(controller,l+1)\n",
    "        size.append(t)\n",
    "        break\n",
    "       else:\n",
    "         t=controller,controller+fold_len+1\n",
    "         size.append(t)\n",
    "         controller=controller+fold_len+1\n",
    "    print(size)\n",
    "    \n",
    "    for k,v in size:\n",
    "        test=digit_dataset[k:v]\n",
    "        train=pd.concat([digit_dataset[0:k],digit_dataset[v:l+1]])\n",
    "        x_train=train[list(train.columns)[1:]]\n",
    "        y_train=train['label']\n",
    "        x_test=test[list(test.columns)[1:]]\n",
    "        y_test=test['label']\n",
    "        mlp.fit(x_train,y_train)\n",
    "        print(\"MLP model : \",mlp)\n",
    "        y_pred=mlp.predict(x_test)\n",
    "        print(\" NN accuracy :\",accuracy_score(y_test,y_pred))\n",
    "        print(\"NN F1 : \",f1_score(y_test,y_pred,average=\"weighted\"))\n",
    "        print(\"NN CM : \",confusion_matrix(y_test,y_pred)) \n",
    "        \n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of folds : \n",
      " 3\n",
      "14000\n",
      "[(0, 14001), (14001, 28002), (28002, 42001)]\n",
      "Iteration 1, loss = 2.56661730\n",
      "Iteration 2, loss = 0.91527839\n",
      "Iteration 3, loss = 0.55281492\n",
      "Iteration 4, loss = 0.34884390\n",
      "Iteration 5, loss = 0.22829928\n",
      "Iteration 6, loss = 0.20262080\n",
      "Iteration 7, loss = 0.18027378\n",
      "Iteration 8, loss = 0.14986018\n",
      "Iteration 9, loss = 0.13799302\n",
      "Iteration 10, loss = 0.14148307\n",
      "Iteration 11, loss = 0.13355422\n",
      "Iteration 12, loss = 0.12200530\n",
      "Iteration 13, loss = 0.13248790\n",
      "Iteration 14, loss = 0.13095316\n",
      "Iteration 15, loss = 0.14399350\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "MLP model :  MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(400,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=True,\n",
      "       warm_start=False)\n",
      " NN accuracy : 0.9569316477394472\n",
      "NN F1 :  0.9570802992397066\n",
      "NN CM :  [[1342    0    3    4    1    3    7    4    7    0]\n",
      " [   0 1501    6    6    5   13    4   10   27    3]\n",
      " [   2    2 1368    9    3    4    3   21   13    2]\n",
      " [   1    0   13 1315    1   60    2    6    9    3]\n",
      " [   1    2    5    1 1286    4    9   15    9   36]\n",
      " [   3    0    1    8    0 1241    8    2   10    3]\n",
      " [  10    1    2    0    4   15 1366    1    1    0]\n",
      " [   0    1    7    2    1    0    0 1438    5   10]\n",
      " [   4    3    4   18    1   46    8    4 1249    6]\n",
      " [   3    0    0    3    6    8    1   43   11 1292]]\n",
      "Iteration 1, loss = 2.56608368\n",
      "Iteration 2, loss = 0.92059116\n",
      "Iteration 3, loss = 0.55931473\n",
      "Iteration 4, loss = 0.34765351\n",
      "Iteration 5, loss = 0.23140894\n",
      "Iteration 6, loss = 0.22757669\n",
      "Iteration 7, loss = 0.17403363\n",
      "Iteration 8, loss = 0.13554974\n",
      "Iteration 9, loss = 0.11544755\n",
      "Iteration 10, loss = 0.13477330\n",
      "Iteration 11, loss = 0.16065145\n",
      "Iteration 12, loss = 0.12148987\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "MLP model :  MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(400,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=True,\n",
      "       warm_start=False)\n",
      " NN accuracy : 0.960431397757303\n",
      "NN F1 :  0.9603823101279825\n",
      "NN CM :  [[1332    0    1    3    4    4    2    0    3    1]\n",
      " [   0 1515    7    1    2    1    2    1    4    0]\n",
      " [   6    5 1337    8    8    0    6    4   21    2]\n",
      " [   2    1   30 1379    3   19    0    5   34   27]\n",
      " [   1    2    5    0 1351    2    6    3    2   16]\n",
      " [   4    2    1   23    2 1177   18    0    8   10]\n",
      " [   7    0    1    0    2    7 1356    0    6    0]\n",
      " [   4    7   17    6   12    5    0 1378    6   25]\n",
      " [   5    4    9    8    9    9   13    1 1286    7]\n",
      " [   5    2    2    6   26    3    0   12    6 1336]]\n",
      "Iteration 1, loss = 2.60378513\n",
      "Iteration 2, loss = 0.94724236\n",
      "Iteration 3, loss = 0.54533581\n",
      "Iteration 4, loss = 0.35798140\n",
      "Iteration 5, loss = 0.30162631\n",
      "Iteration 6, loss = 0.20039168\n",
      "Iteration 7, loss = 0.16454240\n",
      "Iteration 8, loss = 0.17009245\n",
      "Iteration 9, loss = 0.15411652\n",
      "Iteration 10, loss = 0.14582635\n",
      "Iteration 11, loss = 0.12647384\n",
      "Iteration 12, loss = 0.13093512\n",
      "Iteration 13, loss = 0.12625250\n",
      "Iteration 14, loss = 0.12607175\n",
      "Iteration 15, loss = 0.13367262\n",
      "Iteration 16, loss = 0.50057247\n",
      "Iteration 17, loss = 0.19889992\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "MLP model :  MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(400,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=True,\n",
      "       warm_start=False)\n",
      " NN accuracy : 0.9641377339619945\n",
      "NN F1 :  0.9640830385539357\n",
      "NN CM :  [[1382    0    2    0    2    1   10    1    8    5]\n",
      " [   0 1551    5    3    1    1    1    5    8    1]\n",
      " [   5    5 1292   12    2    0    2   16   18    1]\n",
      " [   3    3   11 1386    2   10    1    8   11    6]\n",
      " [   1    2    5    0 1278    0    9    2    1   18]\n",
      " [   6    1    2   25    5 1189    8    3   18   17]\n",
      " [   8    0    0    1    3    2 1342    1    1    0]\n",
      " [   0    1    4    3    8    0    0 1455    1    5]\n",
      " [   3    9    3   16    8    8    7    9 1289   17]\n",
      " [   6    3    2    5   42    4    3   19    7 1332]]\n"
     ]
    }
   ],
   "source": [
    "fold_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.61660937\n",
      "Iteration 2, loss = 0.91107943\n",
      "Iteration 3, loss = 0.58882303\n",
      "Iteration 4, loss = 0.37720593\n",
      "Iteration 5, loss = 0.25502578\n",
      "Iteration 6, loss = 0.23123964\n",
      "Iteration 7, loss = 0.19850647\n",
      "Iteration 8, loss = 0.17358066\n",
      "Iteration 9, loss = 0.16742352\n",
      "Iteration 10, loss = 0.13150119\n",
      "Iteration 11, loss = 0.14205370\n",
      "Iteration 12, loss = 0.10061485\n",
      "Iteration 13, loss = 0.12360830\n",
      "Iteration 14, loss = 0.12454780\n",
      "Iteration 15, loss = 0.12837302\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "MLP model :  MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(400,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=True,\n",
      "       warm_start=False)\n",
      " NN accuracy : 0.9585714285714285\n",
      "NN F1 :  0.9586064344332214\n",
      "NN CM :  [[1330    0    7    2    1    4   12    3   11    1]\n",
      " [   0 1536    5    5    4    0    2    3   18    2]\n",
      " [   0    2 1387    8    4    0    2    7   15    2]\n",
      " [   0    0   19 1331    1   19    2    5   22   11]\n",
      " [   0    1    3    0 1338    2    6    2    6   10]\n",
      " [   2    1    3   19    3 1202    8    3   27    8]\n",
      " [   6    0    1    0    9    6 1366    1   10    0]\n",
      " [   2    5   11    2   12    0    0 1409   11   12]\n",
      " [   0    2    7   13    3   13    4    3 1296    2]\n",
      " [   2    2    4    5   53    4    1   41   30 1225]]\n",
      "Iteration 1, loss = 2.60497767\n",
      "Iteration 2, loss = 0.88865328\n",
      "Iteration 3, loss = 0.54741503\n",
      "Iteration 4, loss = 0.36026616\n",
      "Iteration 5, loss = 0.27064252\n",
      "Iteration 6, loss = 0.18831387\n",
      "Iteration 7, loss = 0.16540549\n",
      "Iteration 8, loss = 0.15747100\n",
      "Iteration 9, loss = 0.15463045\n",
      "Iteration 10, loss = 0.18011415\n",
      "Iteration 11, loss = 0.14869221\n",
      "Iteration 12, loss = 0.12542589\n",
      "Iteration 13, loss = 0.12307162\n",
      "Iteration 14, loss = 0.11599513\n",
      "Iteration 15, loss = 0.11857408\n",
      "Iteration 16, loss = 0.12501859\n",
      "Iteration 17, loss = 0.11140641\n",
      "Iteration 18, loss = 0.14210095\n",
      "Iteration 19, loss = 0.13698901\n",
      "Iteration 20, loss = 0.13383945\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "MLP model :  MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(400,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=True,\n",
      "       warm_start=False)\n",
      " NN accuracy : 0.9597142857142857\n",
      "NN F1 :  0.9597466562700998\n",
      "NN CM :  [[1333    0    2    3    1    2    3    1    2    3]\n",
      " [   0 1517    4    2    3    0    0    2    4    0]\n",
      " [   3   17 1305   33    5    1    2   18   12    1]\n",
      " [   1    1    5 1450    1   16    0    5   16    4]\n",
      " [   4    3    3    1 1350    1    2    6    3   15]\n",
      " [   3    1    0   47    1 1171    6    0   12    4]\n",
      " [  12    1    3    1    4   10 1343    0    6    0]\n",
      " [   3    9    4   18   18    1    0 1390    3   14]\n",
      " [   5    4    9   17    7    6    6    3 1286    8]\n",
      " [   3    1    0   34   41    5    0   11   12 1291]]\n",
      "Iteration 1, loss = 2.65087502\n",
      "Iteration 2, loss = 0.94425016\n",
      "Iteration 3, loss = 0.56039262\n",
      "Iteration 4, loss = 0.36904411\n",
      "Iteration 5, loss = 0.27183918\n",
      "Iteration 6, loss = 0.20169007\n",
      "Iteration 7, loss = 0.15437578\n",
      "Iteration 8, loss = 0.15863296\n",
      "Iteration 9, loss = 0.16617669\n",
      "Iteration 10, loss = 0.11648731\n",
      "Iteration 11, loss = 0.12942308\n",
      "Iteration 12, loss = 0.14419144\n",
      "Iteration 13, loss = 0.12300599\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "MLP model :  MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(400,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=True,\n",
      "       warm_start=False)\n",
      " NN accuracy : 0.9589285714285715\n",
      "NN F1 :  0.9589801763168098\n",
      "NN CM :  [[1391    1    6    0    0    2    9    0    0    2]\n",
      " [   0 1569    2    3    0    1    0    0    1    1]\n",
      " [  11    2 1305    3    3    0    3    9    9    8]\n",
      " [   3    6   17 1380    1   10    0    4    5   16]\n",
      " [   1    9    0    0 1216    0    7    3    5   75]\n",
      " [  12    4    1   37    3 1178    9    2    9   19]\n",
      " [  13    6    4    0    1   11 1314    1    8    0]\n",
      " [   0    3    6    4    8    2    0 1423    2   29]\n",
      " [  14   21    8   12    2    5    5    3 1271   28]\n",
      " [   5    7    2    6    7    4    0    9    5 1378]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "mlp=MLPClassifier(\n",
    "    solver='adam',\n",
    "    alpha=1e-2,\n",
    "    hidden_layer_sizes=(400,),\n",
    "    random_state=1,\n",
    "    verbose=True)\n",
    "fold=KFold(n_splits=3, random_state=42, shuffle=False)\n",
    "x_a=x.values\n",
    "y_a=y.values\n",
    "for train_index,test_index in fold.split(x):\n",
    "    x_train=x_a[train_index]\n",
    "    x_test= x_a[test_index]\n",
    "    y_train=y_a[train_index]\n",
    "    y_test=y_a[test_index]\n",
    "    mlp.fit(x_train,y_train)\n",
    "    print(\"MLP model : \",mlp)\n",
    "    y_pred=mlp.predict(x_test)\n",
    "    print(\" NN accuracy :\",accuracy_score(y_test,y_pred))\n",
    "    print(\"NN F1 : \",f1_score(y_test,y_pred,average=\"weighted\"))\n",
    "    print(\"NN CM : \",confusion_matrix(y_test,y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df=pd.DataFrame({'label':y_pred_test})\n",
    "y_pred_df.to_csv(\"y_predictions.csv\",index=True,index_label='ImageID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.19.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
